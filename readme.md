# ET-data Secondary Face Classifier – IP PAN

This project provides a command-line interface for running a **secondary face classification model** on eye-tracking recordings **acquired using Pupil Labs hardware**.  
It is intended **only as a classifier** and relies on a **pretrained CNN model** (no training included).

---

## Pipeline Overview

For each recording, the pipeline performs the following steps:

1. **Frame extraction**  
   Crops candidate face regions from the scene video using precomputed face detections generated by the *Pupil Labs Face Mapper*.

2. **Classification**  
   Applies a pretrained CNN to perform secondary face / non-face classification on the extracted frames.

3. **Postprocessing**
   - Temporal smoothing of per-frame predictions  
   - Generation of `augmented_face_frames.csv` with refined classifications

4. **Optional HTML visualization**  
   Generates simple, paginated HTML pages for quick visual inspection of face and non-face frames.

After all recordings are processed, the pipeline can **aggregate results across recordings** and **prune gaze/fixation CSVs** accordingly.

---
# Setup (Linux & Windows)

## 1. Clone the project repository

**Linux:**

1. Install Git and Git LFS. Git LFS is required for downloading the classifier.
```bash
# Update package list
sudo apt update

# Install Git (if not already installed)
sudo apt install git

# Install Git LFS (if not already installed)
sudo apt install git-lfs
git lfs install
```
2. Clone the repository
```bash
# Clone the repository
git clone https://github.com/m-wawrzyniak/PAN_secondary_classifier_interface
# Move to the repository
cd PAN_secondary_classifier_interface
```
3. Pull the classifier model via Git FLS
```bash
# Pull the classifier
git lfs pull
```

**Windows:**

1. Install **Git**: [https://git-scm.com/download/win](https://git-scm.com/download/win). It's required to download the classifier interface.
2. Install **Git LFS**: [https://git-lfs.github.com/](https://git-lfs.github.com/). It's required to download the classifier model.
3. Open **PowerShell** and run:
   1. Mount Git LFS:
    ```powershell
    git lfs install
    ```
   2. Clone the repository:
    ```powershell
    git clone https://github.com/m-wawrzyniak/PAN_secondary_classifier_interface
    ```
   3. Pull the classifier model via Git LFS
    ```powershell
    cd PAN_secondary_classifier_interface
    git lfs pull
    ```

>  **Important:** If you downloaded the ZIP from GitHub instead of cloning, the model file will be missing. You **must use Git + Git LFS**.

---

## 2. Ensure Python 3.12 is installed

**Linux:**
1. Check if Python 3.12 is available on your local machine:
```bash
python3.12 --version
```
2. If not, download it:
```bash
sudo apt update
sudo apt install python3.12 python3.12-venv python3.12-dev
```

If the package is not available in your Ubuntu version, you may need to add the deadsnakes PPA:
```bash
sudo apt install software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.12 python3.12-venv python3.12-dev

```

**Windows:**
1. Open **CMD** and run:
   1. Check if Python 3.12 is available:
    ```cmd
    python --version
    ```
   If you have multiple Python versions installed:
    ```cmd
    py -3.12 --version
    ```
   2. If Python 3.12 is not installed, download it: [Python for Windows](https://www.python.org/downloads/release/python-3120/)


---

## 3. Create a virtual environment

**Linux:**

Create the environment, specifying Python 3.12 as the interpreter.
```bash
python3.12 -m venv .sfc_venv
```

Always create the environment in the project root directory.

**Windows:**

Using CMD, run:
1. Navigate to the **project root directory**.
2. Create the environment, specifying Python 3.12 as the interpreter.
```cmd
py -3.12 -m venv .sfc_venv
```

---

## 4. Activate the virtual environment

**Linux:**

```bash
source .sfc_venv/bin/activate
```

**Windows:**

Using CMD within **project root directory**, run:
```cmd
.sfc_venv\Scripts\activate.bat
```


---

## 5. Install dependencies

**Linux/Windows:**

```bash
pip install --upgrade pip
pip install -r requirements.txt

```

Check that the packages installed correctly:

```bash
pip list
```

---

## 6. Download input data

You need **two sources of input**:

1. **Scene videos and timeseries CSVs**  
   - Path: `Workspace → Project → Downloads → Timeseries CSV and Scene Video`  
   - Each recording should be in a separate folder

2. **Face Mapper enrichment output**  
   - Path: `Workspace → Project → Downloads → <Enrichment Name>`  
   - Must contain:
     - `sections.csv`
     - `face_detections.csv`

---

## 7. Run the pipeline

From the **project root directory**:

**Linux:**

```bash
python3 -u source/sec_classification.py \
    --rec_dir_root "/path/to/recordings" \
    --output_root "/path/to/output" \
    --data_root "/path/to/data" \
    --run_range 1 3 \
    --aggregate \
    --html \
    > run.log 2>&1
```

**Windows:**

Run using CMD:

```cmd
python -u source\sec_classification.py --rec_dir_root "\path\to\recordings" --output_root "\path\to\output" --data_root "\path\to\data" --run_range 1 3 --aggregate --html > run.log 2>&1
```

For example, the following arguments can be:
```cmd
--rec_dir_root "D:\Extreme SSD\IP_PAN\Timeseries Data + Scene Video" 
--output_root "D:\Extreme SSD\IP_PAN\results_secondary_classification"
--data_root "D:\Extreme SSD\IP_PAN\Sit&Face_FACE-MAPPER_Faces_Manipulative"
```

### Command-line arguments

| Argument | Description |
|---------|-------------|
| `--rec_dir_root` | Folder containing **Timeseries CSV and Scene Video** data. Each recording must be in a separate subfolder. |
| `--output_root` | Output directory for extracted frames, intermediate data, and results. **Note:** intermediate data may exceed 10 GB. |
| `--data_root` | Folder containing **Face Mapper enrichment** files (`sections.csv`, `face_detections.csv`). |
| `--run_range` | Two integers `[start end]` selecting pipeline stages: 1=extract, 2=classify, 3=postprocess. Default: `[1 3]`. |
| `--aggregate` | Aggregate all per-recording results into a single CSV after processing (recommended). |
| `--smooth_window` | Temporal smoothing window (odd integer, e.g. `3`). Use `0` to disable smoothing. Default: `3`. |
| `--html` | Generate HTML visualizations for manual inspection (recommended). |

---

## 8. Monitor progress

**Linux:**

In separate Terminal window, navigate to **project root directory** and run:
```bash
tail -f run.log
```

**Windows:**

Simply navigate to the **project root directory** and open the **run.log** file when needed. Note: to refresh the file, you need to close it and open again.

---

# Running the classification after the setup:

**Linux:**
1. Navigate to the **project root directory**.
2. Activate the virtual environment.
    ```bash
    source .sfc_venv/bin/activate
    ```
3. Run:
    ```bash
    python3 -u source/sec_classification.py \
    --rec_dir_root "/path/to/recordings" \
    --output_root "/path/to/output" \
    --data_root "/path/to/data" \
    --run_range 1 3 \
    --aggregate \
    --html \
    > run.log 2>&1
    ```

**Windows:**
1. Open CMD and navigate to the **project root directory**.
2. Activate the virtual environment.
    ```cmd
    .sfc_venv\Scripts\activate.bat
    ```
3. Run:
    ```cmd
    python -u source\sec_classification.py --rec_dir_root "\path\to\recordings" --output_root "\path\to\output" --data_root "\path\to\data" --run_range 1 3 --aggregate --html > run.log 2>&1
    ```

---

## Output Structure

For **each recording**, a folder will be created inside `output_root` containing:

- Hundreds of extracted face-frame images
- `model_class.csv` – raw per-frame model predictions (`is_face = 0/1`)
- `face_frames.csv` – intermediate data used internally by the pipeline
- `augmented_face_frames.csv` – final, postprocessed classification results for this recording
- `result_html/` – HTML pages for visual inspection (only if `--html` was used)

If the pipeline is run with `--aggregate`, additional files are created in the **project directory**:

- `aggregated/augmented_face_detections.csv` – combined results from all recordings
- If smoothing is enabled (`--smooth_window != 0`):
  - `fixations_on_faces.csv`
  - `gaze_on_face.csv`

---

## Known issues:

1. Microsoft Visual Studio C++ Redistributable 2015-2022:

    If running the script failed, you may need to download and install the following software: 	https://aka.ms/vc14/vc_redist.x64.exe

## License

This project is licensed under the MIT License. See the LICENSE file for details.

