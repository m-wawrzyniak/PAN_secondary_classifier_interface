# ET-data Secondary Face Classifier – IP PAN

This project provides a command-line interface for running a **secondary face classification model** on eye-tracking recordings **acquired using Pupil Labs hardware**.  
It is intended **only as a classifier** and relies on a **pretrained CNN model** (no training included).

---

## Pipeline Overview

For each recording, the pipeline performs the following steps:

1. **Frame extraction**  
   Crops candidate face regions from the scene video using precomputed face detections generated by the *Pupil Labs Face Mapper*.

2. **Classification**  
   Applies a pretrained CNN to perform secondary face / non-face classification on the extracted frames.

3. **Postprocessing**
   - Temporal smoothing of per-frame predictions  
   - Generation of `augmented_face_frames.csv` with refined classifications

4. **Optional HTML visualization**  
   Generates simple, paginated HTML pages for quick visual inspection of face and non-face frames.

After all recordings are processed, the pipeline can **aggregate results across recordings** and **prune gaze/fixation CSVs** accordingly.

---

## Example Setup

### 1. Download the project

Download or clone the repository to your local machine (e.g. download the ZIP from GitHub and unzip it).

### 2. Ensure Python ≥ 3.10 is installed

Check your Python version:

```bash
python3 --version
```

If Python is not installed, install it using your system package manager or from https://www.python.org.


### 3. Create a virtual environment

From the **project root directory**:

```bash
python3 -m venv .sfc_venv
```

### 4. Activate the virtual environment

```bash
# Linux / macOS
source .sfc_venv/bin/activate

# Windows
.sfc_venv\Scripts\activate
```

### 5. Install dependencies

```bash
pip install -r requirements.txt
```

---

## Usage

### 1. Input data

You need to download the following data from **Pupil Cloud**:

1. **Scene videos and timeseries CSVs**  
   - Path: `Workspace → Project → Downloads → Timeseries CSV and Scene Video`  
   - Each recording should be in a separate folder

2. **Face Mapper enrichment output**  
   - Path: `Workspace → Project → Downloads → <Enrichment Name>`  
   - Must contain:
     - `sections.csv`
     - `face_detections.csv`

---

### 2. Run the pipeline

From the **project root directory**, run:

```bash
python -u source/sec_classification.py \
    --rec_dir_root "/path/to/recordings" \
    --output_root "/path/to/output" \
    --data_root "/path/to/data" \
    [--run_range 1 3] \
    [--aggregate] \
    [--smooth_window 3] \
    [--html] \
    > run.log 2>&1
```

#### Command-line arguments

| Argument | Description |
|---------|-------------|
| `--rec_dir_root` | Folder containing **Timeseries CSV and Scene Video** data. Each recording must be in a separate subfolder. |
| `--output_root` | Output directory for extracted frames, intermediate data, and results. **Note:** intermediate data may exceed 10 GB. |
| `--data_root` | Folder containing **Face Mapper enrichment** files (`sections.csv`, `face_detections.csv`). |
| `--run_range` | Two integers `[start end]` selecting pipeline stages: 1=extract, 2=classify, 3=postprocess. Default: `[1 3]`. |
| `--aggregate` | Aggregate all per-recording results into a single CSV after processing (recommended). |
| `--smooth_window` | Temporal smoothing window (odd integer, e.g. `3`). Use `0` to disable smoothing. Default: `3`. |
| `--html` | Generate HTML visualizations for manual inspection (recommended). |

---

### 3. Monitor progress

To follow progress in real time:

```bash
tail -f run.log
```

### 4. Check if the process is still running

If `run.log` appears inactive for a long time, you can verify that the script is still running:

```bash
ps aux | grep sec_classification.py
```

If the process appears in the list, it is still running. This is expected - the pipeline can take **several hours**, especially during frame extraction and classification.

---

## Output Structure

For **each recording**, a folder will be created inside `output_root` containing:

- Hundreds of extracted face-frame images
- `model_class.csv` – raw per-frame model predictions (`is_face = 0/1`)
- `face_frames.csv` – intermediate data used internally by the pipeline
- `augmented_face_frames.csv` – final, postprocessed classification results for this recording
- `result_html/` – HTML pages for visual inspection (only if `--html` was used)

If the pipeline is run with `--aggregate`, additional files are created in the **project directory**:

- `aggregated/augmented_face_detections.csv` – combined results from all recordings
- If smoothing is enabled (`--smooth_window != 0`):
  - `fixations_on_faces.csv`
  - `gaze_on_face.csv`

---

## License

This project is licensed under the MIT License. See the LICENSE file for details.

